# DEIA Chat Interface

Web-based chat interface for interacting with DEIA projects using local LLMs (Ollama).

## ğŸ“Š Current Status

**Phase:** 1 of 4 (Basic Chat) âœ… Complete
**Progress:** 14% by effort, 25% by phase
**Last Updated:** 2025-10-15

| Phase | Status | Progress |
|-------|--------|----------|
| Phase 1: Basic Chat | âœ… Complete | 100% |
| Phase 2: File Operations | â³ Planned | 0% |
| Phase 3: File Modifications | â³ Planned | 0% |
| Phase 4: Polish | â³ Planned | 0% |

## ğŸš€ Quick Start

### Prerequisites
```bash
# Install and start Ollama
ollama pull qwen2.5-coder:7b
ollama serve
```

### Run the Chat Interface
```bash
cd llama-chatbot
pip install -r requirements.txt
python app.py
```

Open browser: http://localhost:8000

See [QUICKSTART.md](QUICKSTART.md) for detailed instructions.

## ğŸ“š Documentation

**Start Here:**
- **[QUICKSTART.md](QUICKSTART.md)** - Get up and running in 5 minutes
- **[STATUS.md](STATUS.md)** - Detailed implementation status and plan

**Deep Dives:**
- **[ROADMAP_SUMMARY.md](ROADMAP_SUMMARY.md)** - Phase overview and timeline
- **[README_SERVICE.md](README_SERVICE.md)** - LLM service API reference
- **[IMPROVEMENTS.md](IMPROVEMENTS.md)** - What was improved from old service
- **[MIGRATION_SUMMARY.md](MIGRATION_SUMMARY.md)** - Service migration details

**Specifications:**
- **[LLH Spec](../.deia/.projects/simulation_004/gpt-llama-bot-eos-companion.md)** - Original specification
- **[Main Roadmap](../ROADMAP.md)** - DEIA project roadmap (Phase 2.5)

## âœ¨ What Works Now

- âœ… **Chat with local LLM** - Ollama integration with streaming
- âœ… **Multiple providers** - Ollama, DeepSeek, OpenAI support
- âœ… **Real-time streaming** - See responses as they're generated
- âœ… **Conversation history** - Auto-managed with token awareness
- âœ… **Basic commands** - Execute safe shell commands
- âœ… **Retry logic** - Automatic retry with exponential backoff
- âœ… **Error handling** - Comprehensive error categorization

## ğŸ”œ Coming Soon

- â³ **DEIA awareness** - Understand .deia project structure
- â³ **File operations** - Read files with syntax highlighting
- â³ **File browser** - Browse project structure
- â³ **File modifications** - Safe file writing with confirmation
- â³ **Audit logging** - Track all operations
- â³ **Better UI** - Professional styling and UX

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Frontend (Browser)              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Chat UI    â”‚      â”‚ WebSocket  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“                â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Backend (FastAPI)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  WebSocket Handler                 â”‚ â”‚
â”‚  â”‚  - Streaming chat                  â”‚ â”‚
â”‚  â”‚  - Conversation history            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  LLM Service (llm_service.py)     â”‚ â”‚
â”‚  â”‚  - OllamaService                   â”‚ â”‚
â”‚  â”‚  - DeepSeekService                 â”‚ â”‚
â”‚  â”‚  - OpenAIService                   â”‚ â”‚
â”‚  â”‚  - Retry logic                     â”‚ â”‚
â”‚  â”‚  - History management              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“                â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Ollama (Local LLM)             â”‚
â”‚         http://localhost:11434           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ›¡ï¸ Security

**Current:**
- âœ… Localhost-only by default
- âœ… Command whitelist
- âœ… Basic path restrictions

**Planned (Phase 2-3):**
- â³ Project boundary enforcement
- â³ File modification confirmations
- â³ Audit logging
- â³ Directory traversal prevention
- â³ Read-only mode toggle

## ğŸ¯ Goals (from LLH Spec)

Create a secure, user-friendly web interface that enables:
- Full file system operations within DEIA project boundaries
- Real-time chat with local LLM (Ollama)
- File modification capabilities with confirmation workflows
- Integration with DEIA project structure and specifications

## ğŸ“‹ Success Criteria

### Functional Requirements
- âœ… Basic chat interface operational
- â³ File reading capabilities implemented
- â³ File modification with confirmation workflow
- â³ Project structure integration
- âœ… Real-time streaming responses

### Security Requirements
- â³ Project directory boundary enforcement
- â³ File modification confirmation system
- â³ Audit logging implementation
- âœ… Localhost-only access by default
- âœ… Session management

### Performance Requirements
- â³ Sub-second response times for file operations
- âœ… Smooth streaming chat experience
- âœ… Efficient memory usage
- âœ… Reliable WebSocket connections

**Score:** 5/14 criteria met (36%)

## ğŸ”§ API Endpoints

### WebSocket
- `ws://localhost:8000/ws` - Real-time chat with streaming

### REST API
- `GET /` - Web UI
- `GET /api/health` - Health check
- `POST /api/chat` - Non-streaming chat
- `POST /api/execute` - Execute command

**Planned (Phase 2-3):**
- `POST /api/files/read` - Read file
- `POST /api/files/write` - Write file
- `GET /api/files/tree` - Project structure
- `POST /api/files/diff` - Generate diff

## ğŸš§ Development Roadmap

### Phase 1: Basic Chat âœ… (COMPLETED 2025-10-15)
FastAPI + Ollama + WebSocket + Streaming
**Effort:** 6 hours

### Phase 2: File Operations â³ (4-6 weeks)
DEIA awareness + File reading + Project browser
**Effort:** 8-10 hours

### Phase 3: File Modifications â³ (6-8 weeks)
File writing + Confirmation + Audit logging
**Effort:** 12-15 hours

### Phase 4: Polish â³ (Ongoing)
Enhanced UI + Keyboard shortcuts + Session persistence
**Effort:** 6-12 hours

**Total Estimated:** 30-43 hours (14% complete)

See [ROADMAP_SUMMARY.md](ROADMAP_SUMMARY.md) for detailed timeline.

## ğŸ¤ Contributing

This project follows the LLH specification:
`.deia/.projects/simulation_004/gpt-llama-bot-eos-companion.md`

**Before contributing:**
1. Read [STATUS.md](STATUS.md) for current priorities
2. Review the LLH spec for requirements
3. Understand security constraints
4. Follow DEIA principles (DND, ROTG)

## ğŸ“ Files

**Core:**
- `app.py` (635 lines) - Main FastAPI application
- `requirements.txt` - Python dependencies

**LLM Service:**
- `../src/deia/services/llm_service.py` (650 lines) - Unified LLM service
- `../src/deia/services/deepseek_service.py` (deprecated)

**Documentation:**
- `README.md` (this file) - Project overview
- `STATUS.md` - Detailed implementation status
- `QUICKSTART.md` - Getting started guide
- `ROADMAP_SUMMARY.md` - Phase overview
- `README_SERVICE.md` - Service API reference
- `IMPROVEMENTS.md` - Changelog
- `MIGRATION_SUMMARY.md` - Migration guide

## ğŸ› Troubleshooting

**Ollama not responding:**
```bash
# Check Ollama is running
ollama serve

# Test API
curl http://localhost:11434/api/tags
```

**Model not found:**
```bash
# List models
ollama list

# Pull model
ollama pull qwen2.5-coder:7b
```

**WebSocket errors:**
- Check browser console
- Verify port 8000 is free
- Try refreshing the page

See [QUICKSTART.md](QUICKSTART.md#troubleshooting) for more.

## ğŸ“Š Metrics

**Code:**
- Total lines: ~1,300 (app.py + llm_service.py)
- Documentation: ~2,000 lines
- Tests: Not yet implemented

**Features:**
- Completed: 5/14 success criteria (36%)
- Phase completion: 1/4 (25%)
- Effort completion: 6/43 hours (14%)

## ğŸ”— Links

**Project:**
- [Main DEIA Repo](https://github.com/deiasolutions/deia)
- [Main Roadmap](../ROADMAP.md)
- [LLH Specification](../.deia/.projects/simulation_004/gpt-llama-bot-eos-companion.md)

**External:**
- [Ollama](https://ollama.com/) - Local LLM runtime
- [FastAPI](https://fastapi.tiangolo.com/) - Web framework
- [Qwen 2.5 Coder](https://ollama.com/library/qwen2.5-coder) - Default model

## ğŸ“„ License

Same as DEIA project.

---

**Last Updated:** 2025-10-15
**Phase:** 1 of 4 complete
**Next Review:** 2025-10-16
**Status:** Production-ready for Phase 1, Phases 2-4 planned

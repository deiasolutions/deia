{
  "algorithm": "PPO",
  "training_config": {
    "total_timesteps": 100000,
    "n_steps": 2048,
    "batch_size": 256,
    "n_epochs": 10,
    "learning_rate": 0.0003,
    "gamma": 0.99,
    "gae_lambda": 0.95,
    "clip_range": 0.2,
    "network_architecture": [
      256,
      256
    ]
  },
  "evaluation_stats": {
    "n_episodes": 10,
    "mean_score": 0.0,
    "std_score": 0.0,
    "max_score": 0.0,
    "min_score": 0.0,
    "scores": [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ]
  },
  "timestamp": "2025-10-27T13:54:22"
}
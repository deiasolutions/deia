{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEIA Analytics Explorer\n",
    "\n",
    "This notebook provides interactive exploration of DEIA analytics data produced by the local ETL.\n",
    "\n",
    "What you can do here:\n",
    "- Load staging NDJSON tables (sessions, events, heartbeats, etc.)\n",
    "- Inspect row counts and sample records\n",
    "- Plot event distributions and time series\n",
    "- Review heartbeats (last seen per bot)\n",
    "- Summarize sessions, decisions, and action items\n",
    "\n",
    "Note: This assumes the ETL has run (see `.deia/analytics/README.md`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports\n",
    "\n",
    "Imports core libraries. If a library is missing, reads will fallback to the Python standard library JSON lines reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, glob, pathlib, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Optional dependencies\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    HAVE_PANDAS = True\n",
    "except Exception as e:\n",
    "    HAVE_PANDAS = False\n",
    "    print('[warn] pandas/matplotlib not available; using minimal loaders. Error:', e)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 4) if 'plt' in globals() else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Paths\n",
    "\n",
    "The helper below locates the project root (folder containing `.deia`). Adjust `PROJECT_ROOT` manually if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_project_root(start: Path = Path.cwd()) -> Path:\n",
    "    p = start.resolve()\n",
    "    for _ in range(6):\n",
    "        if (p / '.deia').is_dir():\n",
    "            return p\n",
    "        if p.parent == p:\n",
    "            break\n",
    "        p = p.parent\n",
    "    return start.resolve()\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "STAGING_DIR = PROJECT_ROOT / '.deia' / 'analytics' / 'staging'\n",
    "print('PROJECT_ROOT =', PROJECT_ROOT)\n",
    "print('STAGING_DIR  =', STAGING_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Staging Tables (NDJSON)\n",
    "\n",
    "Loads all partitions under `dt=YYYY-MM-DD` for each table. If pandas is available, returns DataFrames. Otherwise, returns lists of dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLES = [\n",
    "    'sessions',\n",
    "    'session_decisions',\n",
    "    'session_action_items',\n",
    "    'session_files_modified',\n",
    "    'events',\n",
    "    'heartbeats',\n",
    "]\n",
    "\n",
    "def load_ndjson_table(table: str, staging_dir: Path = STAGING_DIR):\n",
    "    base = staging_dir / table\n",
    "    files = sorted(base.glob('dt=*/*.ndjson'))\n",
    "    rows = []\n",
    "    for fp in files:\n",
    "        with fp.open('r', encoding='utf-8', errors='replace') as f:\n",
    "            for line in f:\n",
    "                s = line.strip()\n",
    "                if not s:\n",
    "                    continue\n",
    "                try:\n",
    "                    rows.append(json.loads(s))\n",
    "                except Exception:\n",
    "                    continue\n",
    "    if HAVE_PANDAS:\n",
    "        return pd.DataFrame(rows)\n",
    "    return rows\n",
    "\n",
    "DATA = {t: load_ndjson_table(t) for t in TABLES}\n",
    "{t: (len(df) if HAVE_PANDAS else len(df)) for t, df in DATA.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Inventory\n",
    "\n",
    "Row counts per table and a few sample rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, df in DATA.items():\n",
    "    n = len(df) if HAVE_PANDAS else len(df)\n",
    "    print(f'{t}: {n} rows')\n",
    "\n",
    "if HAVE_PANDAS and len(DATA['sessions']) > 0:\n",
    "    display(DATA['sessions'].head(5))\n",
    "if HAVE_PANDAS and len(DATA['events']) > 0:\n",
    "    display(DATA['events'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Types Distribution\n",
    "\n",
    "Bar chart of `event_type` counts across all events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAVE_PANDAS and len(DATA['events']) > 0:\n",
    "    ev = DATA['events'].copy()\n",
    "    if 'event_type' in ev.columns:\n",
    "        counts = ev['event_type'].value_counts().sort_values(ascending=True)\n",
    "        counts.plot(kind='barh', title='Event Types Distribution')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('[info] events table has no event_type column')\n",
    "else:\n",
    "    print('[info] pandas not available or events empty — skipping chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events Over Time\n",
    "\n",
    "Time series of events by day (or hour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAVE_PANDAS and len(DATA['events']) > 0:\n",
    "    ev = DATA['events'].copy()\n",
    "    # Normalize timestamp column heuristically\n",
    "    ts_col = 'ts' if 'ts' in ev.columns else ('timestamp' if 'timestamp' in ev.columns else None)\n",
    "    if ts_col:\n",
    "        ev['_ts'] = pd.to_datetime(ev[ts_col], errors='coerce', utc=True)\n",
    "        daily = ev.dropna(subset=['_ts']).set_index('_ts').resample('D').size()\n",
    "        daily.plot(title='Events per Day')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('[info] could not find timestamp column in events')\n",
    "else:\n",
    "    print('[info] pandas not available or events empty — skipping chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heartbeats — Last Seen Per Bot\n",
    "\n",
    "Shows the most recent heartbeat timestamp by `bot_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAVE_PANDAS and len(DATA['heartbeats']) > 0:\n",
    "    hb = DATA['heartbeats'].copy()\n",
    "    for c in ['ts', 'timestamp']:\n",
    "        if c in hb.columns:\n",
    "            hb['_ts'] = pd.to_datetime(hb[c], errors='coerce', utc=True)\n",
    "            break\n",
    "    if '_ts' in hb.columns and 'bot_id' in hb.columns:\n",
    "        last_seen = hb.dropna(subset=['_ts']).sort_values('_ts').groupby('bot_id')['_ts'].tail(1)\n",
    "        # Convert to DataFrame for plotting\n",
    "        df = hb.loc[last_seen.index, ['bot_id', '_ts']]\n",
    "        df = df.drop_duplicates('bot_id').set_index('bot_id').sort_values('_ts')\n",
    "        df['_ts'].astype('int64') // 10**9  # touch type\n",
    "        df['_ts'].plot(kind='barh', title='Heartbeats — Last Seen per Bot')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('[info] heartbeats missing bot_id or timestamp columns')\n",
    "else:\n",
    "    print('[info] pandas not available or heartbeats empty — skipping chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sessions — Activity Summary\n",
    "\n",
    "Counts of sessions per day, and decision/action item densities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAVE_PANDAS and len(DATA['sessions']) > 0:\n",
    "    ss = DATA['sessions'].copy()\n",
    "    ss['_start'] = pd.to_datetime(ss.get('ts_start', None), errors='coerce', utc=True)\n",
    "    per_day = ss.dropna(subset=['_start']).set_index('_start').resample('D').size()\n",
    "    ax = per_day.plot(title='Sessions per Day')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # Join decisions and action items per session\n",
    "    dec = DATA['session_decisions'] if HAVE_PANDAS else []\n",
    "    act = DATA['session_action_items'] if HAVE_PANDAS else []\n",
    "    if HAVE_PANDAS and len(dec) > 0 and len(act) > 0 and 'session_id' in ss.columns:\n",
    "        dec_c = dec.groupby('session_id').size().rename('decisions')\n",
    "        act_c = act.groupby('session_id').size().rename('action_items')\n",
    "        joined = ss.set_index('session_id').join(dec_c, how='left').join(act_c, how='left').fillna(0)\n",
    "        display(joined[['decisions','action_items']].describe())\n",
    "else:\n",
    "    print('[info] pandas not available or sessions empty — skipping charts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Ideas\n",
    "\n",
    "- Add Parquet export and DuckDB views (Phase 2)\n",
    "- Create `agents` table (derived from events/heartbeats)\n",
    "- Build dashboards for event taxonomy and session outcomes\n",
    "- Add privacy redaction hooks and incremental `--since` loads"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

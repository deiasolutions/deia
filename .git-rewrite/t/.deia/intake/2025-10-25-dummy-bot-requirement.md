# Intake: Dummy Bot Launcher Should Use Llama Bot

**Date:** 2025-10-25
**From:** Dave (User)
**To:** DEIA Hive
**Requirement:** Bot Launcher Enhancement
**Priority:** TBD
**Status:** Logged for assignment

---

## Requirement

When launching a dummy bot from the chat controller window, the launcher should start a **real Llama bot** (using Ollama service) instead of an echo-back mock bot.

**Current Behavior:** Dummy bot launch returns echo responses

**Desired Behavior:** Dummy bot launch starts actual Llama bot service with real LLM responses

---

## Context

- Chat controller is on port 8000
- Bot launcher spawns bots on dynamic ports (8001-8999)
- Currently using mock/echo implementations for testing
- Need real Llama bot integration for realistic testing

---

## Technical Notes

- Ollama service assumed to be running
- Model: qwen2.5-coder:7b (or current default)
- Bot should respond with actual LLM outputs, not mock responses
- Should be compatible with existing bot registry and task queue

---

## Acceptance Criteria

- [ ] Dummy bot launches real Llama service
- [ ] Receives LLM responses instead of echo responses
- [ ] Works with existing bot registry
- [ ] Integrates with task queue system

---

**Awaiting assignment to appropriate bot for implementation.**

---

Generated by BOT-001 logging user requirement
